{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad2cc4e-31ec-4648-b0fe-6632f2bdbc36",
   "metadata": {},
   "source": [
    "## 音声認識モデルとLLMの組み合わせ\n",
    "\n",
    "このNotebookでは、OpenShift AIでServingされた音声認識モデルのFaster-Whisperを利用して音声から文章を起こし、LLMを使用して請求文章を分析し、話し手の心理状態や事故の場所と日時を特定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c941e8-7510-471e-ac55-813fe71723e5",
   "metadata": {},
   "source": [
    "### 必要なライブラリとインポート\n",
    "\n",
    "Labの指示に従って適切なワークベンチイメージを選択して起動した場合、必要なすべてのライブラリがすでにインストールされているはずです。もしインストールされていない場合は、次のセルの最初の行のコメントを外して正しいパッケージをすべてインストールしてください。その後、必要なライブラリをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c595d-967e-47de-a598-02b5d1ccec85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --no-cache-dir --no-dependencies --disable-pip-version-check -r requirements.txt # Uncomment only if you have not selected the right workbench image\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import VLLMOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.chat import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797789e-45c3-4679-9294-f699a3cb4e34",
   "metadata": {},
   "source": [
    "### 音声認識モデルのAPIクライアント\n",
    "\n",
    "音声認識モデルのAPIを呼び出すクライアントを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c03f4d6-3c95-4626-b247-bcd28bf09307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声認識モデルのAPIのURL\n",
    "transcription_server_url = \"_INFERENCE_URL_TRANSCRIPTION_\"\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_client = OpenAI(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url= f\"{transcription_server_url}/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b3ad1-ece7-482e-a0a5-669fb415995f",
   "metadata": {},
   "source": [
    "### Langchainパイプライン\n",
    "\n",
    "Langchainを使用して、パイプラインを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9159b-357f-4e13-9e2b-a7569b49dcb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM推論APIのURL\n",
    "inference_server_url = \"_INFERENCE_URL_LLM_\"\n",
    "\n",
    "# LLMの定義\n",
    "llm = VLLMOpenAI(\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    openai_api_base= f\"{inference_server_url}/v1\",\n",
    "    model_name=\"/mnt/models/\",\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3450d8-ba36-4524-8131-547a7a167ef0",
   "metadata": {},
   "source": [
    "以下は、タスクに対してフォーマットされた**テンプレート**です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1172dc2a-c0af-462e-ac36-64f4c7f6063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template_string = \"\"\"\n",
    "あなたは、親切で、礼儀正しく、正直なアシスタントです。\n",
    "常に気配りと尊重をもって接し、真摯にサポートします。できる限り有用な返答を提供しますが、安全を確保します。\n",
    "有害で、倫理に反する、偏見のある、または否定的な内容は避けます。返答が公正でポジティブなものであることを確認します。\n",
    "\"\"\"\n",
    "\n",
    "user_template_string = \"\"\"\n",
    "与えられた文章の内容をもとに、与えられた質問に答えてください。\n",
    "\n",
    "### 文章:\n",
    "{text}\n",
    "\n",
    "### 質問:\n",
    "{query}\n",
    "\n",
    "### 回答:\n",
    "\"\"\"\n",
    "\n",
    "system_template = SystemMessagePromptTemplate.from_template(system_template_string)\n",
    "user_template = HumanMessagePromptTemplate.from_template(user_template_string)\n",
    "\n",
    "PROMPT = ChatPromptTemplate.from_messages([system_template, user_template])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178054b5-0068-4d82-90b8-b41cbe7a4e75",
   "metadata": {},
   "source": [
    "モデルにクエリを投げるために使用する**会話**オブジェクトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d9f32-d4ae-4c2f-b513-d520413d2cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation = LLMChain(llm=llm,\n",
    "                        prompt=PROMPT,\n",
    "                        verbose=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9b689-e7a2-4372-99a0-effc3b67f491",
   "metadata": {},
   "source": [
    "モデルにクエリする準備が整いました。\n",
    "\n",
    "`voices`フォルダーには、音声の例が保存されています。これらのファイルを読み込んで文字起こしを行い、それに対してLLMが行った分析を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca714bca-7cec-4afc-b275-fa389c05a993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "voices_path = 'voices'\n",
    "onlyfiles = [f for f in listdir(voices_path) if isfile(join(voices_path, f))]\n",
    "\n",
    "voices = {}\n",
    "\n",
    "for filename in onlyfiles:\n",
    "    audio_file= open(os.path.join(voices_path, filename), \"rb\")\n",
    "    transcription = openai_client.audio.transcriptions.create(\n",
    "      model=\"\",\n",
    "      file=audio_file\n",
    "    )\n",
    "\n",
    "    print(f\"***************************\")\n",
    "    print(f\"* 請求: {filename}\")\n",
    "    print(f\"***************************\")\n",
    "    print(\"元の音声メッセージ:\")\n",
    "    print(\"-----------------\")\n",
    "    print(transcription.text)\n",
    "    print('\\n\\n分析:')\n",
    "    print(\"--------\")\n",
    "    text_input = transcription.text\n",
    "    sentiment_query = \"この請求の文章から読み取れる感情はどのようなものですか？「肯定的」、「否定的」、「どちらでもない」から1つだけ選んで答え、その理由もあわせて説明してください。\"\n",
    "    location_query = \"この請求に関連する出来事はどこで起こりましたか？出来事の発生した場所について、市区町村や通りの名前などを答えて下さい。\"\n",
    "    time_query = \"この請求に関連する出来事はいつ起こりましたか？日付と、時刻あるいは時間帯を一言で答えて下さい。\"\n",
    "    print(f\"- 送信者の感情: \")\n",
    "    conversation.predict(text=text_input, query=sentiment_query);\n",
    "    print(\"\\n- 発生場所: \")\n",
    "    conversation.predict(text=text_input, query=location_query);\n",
    "    print(\"\\n- 発生日時: \")\n",
    "    conversation.predict(text=text_input, query=time_query);\n",
    "    print(\"\\n\\n                          ----====----\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
